## DeepLearningHandsOn

It's time for me to start taking DeepLearning seriously, and the best way to learn is to implement papers.

I'll try to document my journey here, but for now I'm also gonna be dumping the code here like jupyter notebooks, until I start having bigger projects and having a repository for each one.

I must start implementing papers:

- (bonus) [micrograd](https://github.com/karpathy/micrograd)
- Attention paper
- Transformers (Attention is all you need)
- An image is worth 16x16 words
- GPT2 (maybe use this as a reference: https://github.com/karpathy/minGPT)
- LLama
- follow https://github.com/karpathy/nanoGPT

## Computer vision recommendations by Saud Alrasheed

1. build your own ResNet. 
2. Style Transfer Network:
    - Transfer styles from one network to an image.
    - Build a network that does (a)
    - DeepDream.
3. Segmentation Tasks:
    - Buid U-Net.
    - Build Deeplab and Deeplab+
4. Generative Models:
    - Build conditional GAN: DCGAN
    - Build simple Diffusion Model (Hot Topic!!! --  very important)
    - Master StyleGAN.
5. Transformers for vision:
  - Build an image is worth 16x16 words.
6. Study 3D Models:
    - Nerf: look at EG3D.
    - Point Cloud: Build PointNet.
7. Domain Adaptation:
    - Build ProtoNet.

## Courses to take

- linear algebra - https://www.youtube.com/watch?v=J7DzL2_Na80
- graph theory course - http://www.maths.lse.ac.uk/Personal/jozef/LTCC/Graph_Theory_Bondy_Murty.pdf
- logic representation course
